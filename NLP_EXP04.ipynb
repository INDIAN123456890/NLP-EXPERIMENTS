{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## **1. Import Libraries**"
      ],
      "metadata": {
        "id": "z0sCvWqgzTXX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "xJ0fMDUNwFYk"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "from nltk.corpus import gutenberg\n",
        "from nltk import word_tokenize\n",
        "from collections import Counter, defaultdict\n",
        "import random\n",
        "import string"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('punkt')\n",
        "nltk.download('punkt_tab')\n",
        "nltk.download('gutenberg')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QzCWCyUyzgpu",
        "outputId": "14aa8292-2c70-492f-ea43-5f124414c2fa"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n",
            "[nltk_data] Downloading package gutenberg to /root/nltk_data...\n",
            "[nltk_data]   Package gutenberg is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **2. Load and Preprocess the Corpus**"
      ],
      "metadata": {
        "id": "NM-ah_wNzwRf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "raw_text = gutenberg.raw('austen-emma.txt')"
      ],
      "metadata": {
        "id": "iy_v2Bsvzp-d"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokens = word_tokenize(raw_text.lower())\n",
        "tokens = [word for word in tokens if word.isalpha()]"
      ],
      "metadata": {
        "id": "b9JnLvyyz6RQ"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **3. Build N-gram Models**"
      ],
      "metadata": {
        "id": "-ex3tQqi0Hzh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Unigram\n",
        "unigram_counts = Counter(tokens)\n",
        "\n",
        "# Bigram\n",
        "bigrams = list(nltk.bigrams(tokens))\n",
        "bigram_counts = Counter(bigrams)\n",
        "\n",
        "# Trigram\n",
        "trigrams = list(nltk.trigrams(tokens))\n",
        "trigram_counts = Counter(trigrams)"
      ],
      "metadata": {
        "id": "__W-F2aFz9Hu"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **4. Estimate Probabilities**"
      ],
      "metadata": {
        "id": "xd4T08un0UlR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# For unigrams: P(w) = count(w) / total_words\n",
        "total_unigrams = sum(unigram_counts.values())\n",
        "unigram_prob = {word: count / total_unigrams for word, count in unigram_counts.items()}\n",
        "\n",
        "# For bigrams: P(w2|w1) = count(w1, w2) / count(w1)\n",
        "bigram_prob = defaultdict(dict)\n",
        "for (w1, w2), count in bigram_counts.items():\n",
        "    bigram_prob[w1][w2] = count / unigram_counts[w1]\n",
        "\n",
        "# For trigrams: P(w3|w1,w2) = count(w1, w2, w3) / count(w1, w2)\n",
        "trigram_prob = defaultdict(dict)\n",
        "bigram_pairs = Counter(list(nltk.bigrams(tokens)))\n",
        "for (w1, w2, w3), count in trigram_counts.items():\n",
        "    trigram_prob[(w1, w2)][w3] = count / bigram_pairs[(w1, w2)]"
      ],
      "metadata": {
        "id": "QqAZgeZT0QuO"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **5. Implement Word Prediction**"
      ],
      "metadata": {
        "id": "RxrVWAfA0gv5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_next_word(input_text, top_k=3):\n",
        "    words = input_text.lower().split()\n",
        "    if len(words) == 1:\n",
        "        w1 = words[0]\n",
        "        if w1 in bigram_prob:\n",
        "            sorted_probs = sorted(bigram_prob[w1].items(), key=lambda x: x[1], reverse=True)\n",
        "            return sorted_probs[:top_k]\n",
        "    elif len(words) >= 2:\n",
        "        w1, w2 = words[-2], words[-1]\n",
        "        if (w1, w2) in trigram_prob:\n",
        "            sorted_probs = sorted(trigram_prob[(w1, w2)].items(), key=lambda x: x[1], reverse=True)\n",
        "            return sorted_probs[:top_k]\n",
        "    return [(\"No prediction\", 0.0)]"
      ],
      "metadata": {
        "id": "9oHpEkVj0d4j"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **6. Evaluate Results**"
      ],
      "metadata": {
        "id": "pj7Rkm1W0txO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "while True:\n",
        "    user_input = input(\"Enter one or two words (or 'exit' to quit): \")\n",
        "    if user_input.lower() == 'exit':\n",
        "        break\n",
        "    predictions = predict_next_word(user_input)\n",
        "    print(\"Predicted next words:\")\n",
        "    for word, prob in predictions:\n",
        "        print(f\"{word} (Prob: {prob:.4f})\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AkNlQzJ20pRg",
        "outputId": "ef0fa970-944f-4986-8825-39bf7680f201"
      },
      "execution_count": 11,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter one or two words (or 'exit' to quit): I am\n",
            "Predicted next words:\n",
            "sure (Prob: 0.2716)\n",
            "not (Prob: 0.0812)\n",
            "very (Prob: 0.0711)\n",
            "Enter one or two words (or 'exit' to quit): How are\n",
            "Predicted next words:\n",
            "you (Prob: 0.5000)\n",
            "they (Prob: 0.5000)\n",
            "Enter one or two words (or 'exit' to quit): He is not\n",
            "Predicted next words:\n",
            "a (Prob: 0.0887)\n",
            "the (Prob: 0.0645)\n",
            "it (Prob: 0.0565)\n",
            "Enter one or two words (or 'exit' to quit): exit\n"
          ]
        }
      ]
    }
  ]
}